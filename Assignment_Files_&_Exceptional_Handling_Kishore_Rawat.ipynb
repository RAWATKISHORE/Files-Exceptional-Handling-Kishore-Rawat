{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Files & Exceptional Handling : Kishore Rawat"
      ],
      "metadata": {
        "id": "TNc_LXiKx_MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where  multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "CfTRyrj6yIvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Multithreading vs. Multiprocessing: When to Use Each\n",
        "\n",
        "##1. Multithreading:\n",
        "###Multithreading is generally preferable when tasks involve I/O-bound operations, such as reading/writing from files, network requests, or database queries, where the processor spends a lot of time waiting for external operations to complete. In these scenarios, multiple threads can be used to perform different operations simultaneously, sharing the same memory space, which makes context-switching between them lightweight and fast.\n",
        "\n",
        "##Scenarios where multithreading is preferable:\n",
        "\n",
        "### I/O-bound tasks: These include operations that involve file systems, network requests, and database queries.\n",
        "  \n",
        "### Example: Web scraping where multiple pages need to be fetched simultaneously.\n",
        "\n",
        "### Shared memory access: When threads need to share memory, such as for updating shared data structures without requiring heavy synchronization.\n",
        "\n",
        "### Example: Real-time applications like web servers that need to handle many user requests efficiently.\n",
        "\n",
        "### Low memory overhead: Since threads share the same memory space, multithreading is more memory efficient compared to multiprocessing.\n",
        "\n",
        "### Example: GUI applications where responsiveness is important and background tasks can be handled in threads.\n",
        "\n",
        "## Advantages of multithreading:**\n",
        "\n",
        "### Faster context switching between threads since they reside in the same memory space.\n",
        "\n",
        "### Less memory overhead because threads share the same memory.\n",
        "\n",
        "### Efficient for tasks where CPU utilization is low due to waiting on I/O.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 2. Multiprocessing:\n",
        "\n",
        "### Multiprocessing, on the other hand, is preferable for CPU-bound tasks, where processes are computationally heavy and require full use of CPU cores. Each process runs in its own memory space, making it suitable for parallel execution of tasks that require a lot of computation.\n",
        "\n",
        "## Scenarios where multiprocessing is preferable:\n",
        "\n",
        "### CPU-bound tasks: These are tasks that require heavy computation, such as numerical calculations, data processing, or machine learning model training.\n",
        "\n",
        "### Example: Processing large datasets or running complex mathematical simulations.\n",
        "\n",
        "### Parallelism with multiple cores: When the program needs to fully utilize the CPU by running tasks on different cores.\n",
        "\n",
        "### Example: Image processing or video rendering where parallel tasks can be split across cores.\n",
        "\n",
        "### Tasks that require isolation:** When tasks are independent and don't need to share data or state, multiprocessing ensures they run in separate memory spaces.\n",
        "\n",
        "### Example: Running multiple independent simulations where shared state is not needed.\n",
        "  \n",
        "## Advantages of multiprocessing:**\n",
        "\n",
        "### True parallelism: Processes can run in parallel on multiple CPU cores, offering significant performance gains for CPU-bound tasks.\n",
        "\n",
        "### Isolation: Each process has its own memory space, so there's no risk of race conditions over shared data without explicit communication via inter-process communication (IPC).\n",
        "\n",
        "### Scalability: Works better with CPU-heavy workloads that benefit from splitting tasks across multiple processes."
      ],
      "metadata": {
        "id": "5A6rCOaCyIoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Gg-dHJU4yIgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "yQuXxVYQyIZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Process Pool:\n",
        "\n",
        "### A process pool is a collection of worker processes that are pre-created and managed, enabling efficient execution of tasks in parallel. Instead of creating a new process for each task, which can be resource-intensive, a process pool allows multiple tasks to be distributed across a fixed number of processes that are reused. This method of pooling helps optimize system resources, such as memory and CPU, and reduces the overhead of process creation and destruction.\n",
        "\n",
        "## How Process Pools Work\n",
        "\n",
        "### In a process pool, you define a specific number of processes that will be available for task execution. When tasks are submitted, they are distributed among these processes, and as each task finishes, the next task in the queue is assigned to the next available process. The pool ensures that no more than the specified number of processes are running simultaneously, balancing workload and maximizing CPU usage.\n",
        "\n",
        "### In Python, the `multiprocessing.Pool` class is commonly used for this purpose. Here’s how it generally works:\n",
        "- A task is submitted to the pool, usually as a function.\n",
        "- The pool assigns the task to one of its worker processes.\n",
        "- Once the task is completed, the process becomes free and can take another task.\n",
        "- This cycle continues until all tasks are completed.\n",
        "\n",
        "## Benefits of Using a Process Pool\n",
        "\n",
        "1. Efficient resource management:\n",
        "   - Reusing processes prevents the overhead of creating and destroying processes repeatedly. This leads to faster execution and less system strain.\n",
        "  \n",
        "2. Parallelism without manual process management:\n",
        "   - The pool manages the distribution of tasks across multiple processes automatically, removing the need for the developer to manually handle processes and inter-process communication.\n",
        "  \n",
        "3. Scalability:\n",
        "   - Process pools allow for easy scaling of parallelism by simply increasing the pool size to match the number of available CPU cores. This enables better utilization of multi-core processors.\n",
        "\n",
        "4. Load balancing:\n",
        "   - Tasks are assigned to the next available worker process, which helps balance the load. Long-running tasks don't block other tasks from being executed in parallel, ensuring smooth and efficient processing.\n",
        "\n",
        "5. Simplified error handling:\n",
        "   - Since tasks are run within the pool, errors or exceptions within a single task don’t affect the entire application. The process pool can handle these situations gracefully by isolating faulty tasks.\n",
        "\n",
        "## Example Usage of Process Pool in Python"
      ],
      "metadata": {
        "id": "QvzHZyhD0wx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a process pool with 4 workers\n",
        "    with Pool(4) as p:\n",
        "        # Map the function 'square' to a list of numbers\n",
        "        result = p.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    print(result)  # Output: [1, 4, 9, 16, 25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVx9E2Rl1BAu",
        "outputId": "e79ed87e-64a3-4703-fc62-eb7e0c427765"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4_7iYQQo0y-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "_kNObRX30y2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Multiprocessing?\n",
        "\n",
        "### Multiprocessing refers to the technique of using multiple processes to execute tasks concurrently. Each process runs in its own memory space, independent of others, and can be executed on multiple CPU cores simultaneously. This enables true parallelism, where different tasks can be performed at the same time, taking full advantage of multi-core processors.\n",
        "\n",
        "### In Python, the `multiprocessing` module provides an interface to create and manage processes, allowing developers to write parallel programs easily. This module overcomes the limitations of the Global Interpreter Lock (GIL), which restricts multithreaded Python programs from fully utilizing multiple cores.\n",
        "\n",
        "## Why is Multiprocessing Used in Python?\n",
        "\n",
        "1. **Overcoming the Global Interpreter Lock (GIL):**\n",
        "   - The GIL is a mechanism in the CPython interpreter that allows only one thread to execute Python bytecode at a time. This means even in a multithreaded program, only one thread can execute in the Python interpreter at any given moment, which limits the benefits of threading in CPU-bound tasks.\n",
        "   - **Multiprocessing bypasses the GIL** because each process has its own Python interpreter and memory space. This allows multiple processes to run truly in parallel, fully utilizing all CPU cores.\n",
        "\n",
        "2. **True parallelism for CPU-bound tasks:**\n",
        "   - **CPU-bound tasks** are operations that require a significant amount of computational power, such as numerical computations, data processing, and machine learning. Using multiprocessing, these tasks can be divided among multiple processes and executed in parallel, speeding up the execution time.\n",
        "   - Example: Performing matrix operations or training machine learning models.\n",
        "\n",
        "3. **Independent memory spaces:**\n",
        "   - Each process in multiprocessing runs in its own memory space, ensuring complete isolation between processes. This avoids problems like race conditions or conflicts over shared memory, which are common in multithreading.\n",
        "   - This makes multiprocessing safer and easier to reason about when performing tasks that don’t need to share data directly.\n",
        "\n",
        "4. **Improved performance for parallel tasks:**\n",
        "   - Tasks that can be easily divided into smaller independent subtasks benefit from multiprocessing. For example, image processing, data analysis, and simulations often need to process large datasets, which can be split and executed concurrently across multiple cores.\n",
        "   - Example: Processing chunks of large datasets in parallel to reduce processing time.\n",
        "\n",
        "5. **Better handling of long-running tasks:**\n",
        "   - Multiprocessing helps in running long, independent tasks in parallel, which is useful for batch processing, background processing, and tasks that require high computation, without blocking the main application.\n",
        "\n",
        "## Example Usage of Multiprocessing in Python\n",
        "\n",
        "### Here’s an example of how to use the `multiprocessing` module in Python:\n"
      ],
      "metadata": {
        "id": "MH6T66Pn0yrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def worker_function(num):\n",
        "    print(f'Worker {num} is processing...')\n",
        "    return num * num\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool of processes\n",
        "    with multiprocessing.Pool(4) as pool:\n",
        "        # Distribute tasks among processes\n",
        "        results = pool.map(worker_function, [1, 2, 3, 4])\n",
        "\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOwAmn39HAOZ",
        "outputId": "aee98c44-b8e2-4f08-805c-4023842ea804"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker 2 is processing...Worker 1 is processing...\n",
            "\n",
            "Worker 3 is processing...Worker 4 is processing...\n",
            "\n",
            "[1, 4, 9, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Use Cases for Multiprocessing:\n",
        "\n",
        "- **CPU-bound operations:** Running heavy computations, such as mathematical simulations, data processing, and machine learning, where parallel execution can significantly reduce the time taken.\n",
        "  \n",
        "- **Task parallelism:** Dividing a task into independent units of work that can be performed in parallel, such as batch processing large datasets or performing background operations.\n",
        "\n",
        "- **Multicore CPU utilization:** Modern CPUs have multiple cores, and multiprocessing allows Python programs to utilize these cores efficiently, maximizing performance."
      ],
      "metadata": {
        "id": "3IXCj_0qGtgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XuonKAd2GtWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "_oN1GFAfGtM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Here's a Python program that demonstrates multithreading, where one thread adds numbers to a list and another thread removes numbers from the list. To avoid **race conditions**, we'll use a `threading.Lock` to ensure that only one thread can modify the list at a time.\n",
        "\n",
        "### Python Program Using Multithreading with `threading.Lock`"
      ],
      "metadata": {
        "id": "lWkI7_e8GtCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared resource (a list)\n",
        "shared_list = []\n",
        "\n",
        "# Create a lock object to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    while True:\n",
        "        number = random.randint(1, 100)\n",
        "        with list_lock:\n",
        "            shared_list.append(number)\n",
        "            print(f\"Added: {number} | List: {shared_list}\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate variable time to add numbers\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    while True:\n",
        "        with list_lock:\n",
        "            if shared_list:\n",
        "                number = shared_list.pop(0)\n",
        "                print(f\"Removed: {number} | List: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting to remove...\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate variable time to remove numbers\n",
        "\n",
        "# Create two threads: one for adding and one for removing numbers\n",
        "add_thread = threading.Thread(target=add_numbers)\n",
        "remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start both threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Let both threads run indefinitely\n",
        "add_thread.join()\n",
        "remove_thread.join()"
      ],
      "metadata": {
        "id": "zhdCcgY1JmTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "1. Shared Resource (List):\n",
        "   - `shared_list`: This is the list that both threads will modify—one thread will add numbers to it, and another will remove numbers.\n",
        "\n",
        "2. Locking Mechanism:\n",
        "   - `list_lock`: A `threading.Lock` object is used to ensure that only one thread can modify the list at a time, avoiding race conditions.\n",
        "   - `with list_lock`: This ensures that whenever a thread enters the critical section (the part where the shared list is modified), it acquires the lock, preventing the other thread from accessing the list at the same time.\n",
        "\n",
        "3. Adding Numbers:\n",
        "   - The `add_numbers` function continuously generates a random number and adds it to the list. It acquires the lock before modifying the list and releases the lock after the number is added.\n",
        "\n",
        "4. Removing Numbers:\n",
        "   - The `remove_numbers` function continuously checks if there are numbers in the list. If so, it removes the first number from the list. It acquires the lock before modifying the list and releases it afterward. If the list is empty, it prints a message indicating that it's waiting to remove.\n",
        "\n",
        "5. Multithreading:\n",
        "   - Two threads are created, `add_thread` for adding numbers and `remove_thread` for removing numbers. Both threads are started and run concurrently.\n",
        "   - `join()` is called to ensure the main program waits for both threads to complete (though in this case, the threads run indefinitely).\n",
        "\n",
        "## Race Condition Prevention:\n",
        "- The **lock** ensures that only one thread can access and modify the shared resource at any given time, preventing the two threads from conflicting with each other, which would cause a race condition."
      ],
      "metadata": {
        "id": "69ulJrsUGssG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CyslCxyUJT10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
      ],
      "metadata": {
        "id": "ZnD28ZUVJTuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In Python, sharing data between threads and processes must be handled carefully to avoid race conditions, deadlocks, and data corruption. Python provides several methods and tools to safely share data between threads and processes, ensuring that concurrent access is properly synchronized. The tools available differ depending on whether you are working with threads (which share the same memory space) or processes (which have separate memory spaces).\n",
        "1. Sharing Data Between Threads\n",
        "Threads share the same memory space, which makes data sharing straightforward but also introduces risks of race conditions when multiple threads access and modify shared data simultaneously. Python provides the following tools to manage this:\n",
        "\n",
        "a) Locks (threading.Lock)\n",
        "A Lock is used to synchronize access to shared resources. Only one thread can acquire the lock at a time, ensuring that no two threads can modify the shared resource concurrently.\n",
        "\n",
        "Example:*"
      ],
      "metadata": {
        "id": "qmOHqz_Y7yVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "shared_list = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_to_list(item):\n",
        "    with lock:  # Acquire lock before modifying the list\n",
        "        shared_list.append(item)"
      ],
      "metadata": {
        "id": "jsN9xZi67y8s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) **RLocks (threading.RLock)**\n",
        "   - A **reentrant lock** (RLock) is similar to a regular lock, but it can be **acquired multiple times by the same thread** without causing a deadlock. It’s useful when a thread needs to acquire the lock recursively.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "g2JAb8Ie8GvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock = threading.RLock()"
      ],
      "metadata": {
        "id": "9O_bePOh8Gg4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) **Conditions (threading.Condition)**\n",
        "   - A `Condition` allows threads to **wait until a certain condition is met** before continuing execution. It combines a `Lock` with signaling, which can be useful for managing coordination between threads (e.g., when one thread waits for another to finish)."
      ],
      "metadata": {
        "id": "4Ajp6Y5g8RO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition = threading.Condition()\n",
        "with condition:\n",
        "    condition.wait()  # Wait until condition is notified"
      ],
      "metadata": {
        "id": "XQqogXCH9kz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) **Queues (queue.Queue)**\n",
        "   - A `Queue` is one of the safest ways to share data between threads. It provides a **thread-safe, FIFO (First In, First Out) data structure**. Threads can safely enqueue or dequeue items without the need for manual locking.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "8yJuLxns8luf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "\n",
        "q = queue.Queue()\n",
        "\n",
        "# Thread 1 adds items\n",
        "q.put(5)\n",
        "\n",
        "# Thread 2 removes items\n",
        "item = q.get()"
      ],
      "metadata": {
        "id": "lnYnxj1z8leF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e) **Event (threading.Event)**\n",
        "   - An `Event` is a simple flag that can be used to **signal** between threads. One thread can set or clear the event, and other threads can wait for the event to be set.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "-ZOZPhAu8xtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = threading.Event()\n",
        "\n",
        "def worker():\n",
        "    event.wait()  # Wait until the event is set\n",
        "    print(\"Event triggered!\")"
      ],
      "metadata": {
        "id": "hlJr_nDi8xa6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Sharing Data Between Processes**\n",
        "\n",
        "Since processes do not share memory, sharing data between processes requires **inter-process communication (IPC)**. Python’s `multiprocessing` module provides several methods to handle data safely across processes.\n",
        "\n",
        "#### a) **Queues (multiprocessing.Queue)**\n",
        "   - A `Queue` is a **process-safe, FIFO data structure** for passing data between processes. The `multiprocessing.Queue` handles the complexities of managing shared data between processes automatically.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "kg-XwkqX89xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def worker(queue):\n",
        "    queue.put(5)  # Add data to queue\n",
        "\n",
        "p = Process(target=worker, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "print(q.get())  # Get data from queue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CAZCmMT89gB",
        "outputId": "d179a8a5-17b3-4588-cdec-7b54f7487dda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) **Pipes (multiprocessing.Pipe)**\n",
        "   - A `Pipe` provides a **two-way communication channel** between processes. It is simpler than a `Queue` but is limited to communication between two processes.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "yX6Kpa5G9vli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pipe\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "\n",
        "def worker(conn):\n",
        "    conn.send(\"Hello from child process!\")\n",
        "\n",
        "p = Process(target=worker, args=(child_conn,))\n",
        "p.start()\n",
        "print(parent_conn.recv())  # Receive data from child"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0lkag_C9vT5",
        "outputId": "e82fb34c-a4e3-4331-d7f9-d7584e477c07"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from child process!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) **Shared Memory (multiprocessing.Value, multiprocessing.Array)**\n",
        "   - `Value` and `Array` are used to share **simple data types** (like integers or floats) and **arrays** between processes. They reside in shared memory, but access to them must be synchronized using locks.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "7l0WnyO695Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Value, Array\n",
        "\n",
        "num = Value('i', 0)  # Shared integer\n",
        "arr = Array('i', [1, 2, 3])  # Shared array"
      ],
      "metadata": {
        "id": "jN69y8bs95GY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) **Managers (multiprocessing.Manager)**\n",
        "   - A `Manager` allows you to create **shared objects** like lists, dictionaries, and queues that can be accessed by multiple processes. The manager takes care of synchronization behind the scenes.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "r8QCWChE-Dmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Manager\n",
        "\n",
        "manager = Manager()\n",
        "shared_list = manager.list()  # Shared list"
      ],
      "metadata": {
        "id": "o2fe4azQ-DSX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e) **Locks and Semaphores (multiprocessing.Lock, multiprocessing.Semaphore)**\n",
        "   - Similar to `threading.Lock`, `multiprocessing.Lock` provides a way to synchronize access to shared resources across processes. A `Semaphore` is useful when you want to limit the number of processes that can access a resource simultaneously.\n",
        "\n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "rwCfkJYQJTfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Lock\n",
        "\n",
        "lock = Lock()"
      ],
      "metadata": {
        "id": "EjxUi5PKNEyA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hRnM-Gd7JTVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "onPT8Ymp3mMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Importance of Handling Exceptions in Concurrent Programs\n",
        "\n",
        "In concurrent programs (whether multithreaded or multiprocess), it is crucial to handle exceptions effectively because:\n",
        "\n",
        "1. **Uncaught Exceptions Can Crash Threads or Processes:**\n",
        "   - If an exception is not caught in a thread or process, it can cause that thread or process to terminate unexpectedly. This can lead to partial completion of tasks, data corruption, or inconsistent states.\n",
        "\n",
        "2. **Resource Leaks:**\n",
        "   - Unhandled exceptions may prevent threads or processes from releasing resources properly, leading to resource leaks such as memory, file handles, or network connections being left open indefinitely.\n",
        "\n",
        "3. **Difficult Debugging:**\n",
        "   - If exceptions are not handled, errors may go unnoticed, especially in multithreaded or multiprocess programs where the output of different threads or processes may be interleaved. This makes debugging and troubleshooting more difficult.\n",
        "\n",
        "4. **Program State Consistency:**\n",
        "   - Exceptions can disrupt the normal flow of execution, potentially leaving shared resources or data in an inconsistent state. Handling exceptions allows you to ensure that cleanup is performed and the system remains stable.\n",
        "\n",
        "5. **Graceful Shutdown:**\n",
        "   - Proper exception handling enables programs to shut down gracefully. If one part of the program encounters an error, other parts can continue to function, or the program can safely shut down without data loss or corruption.\n",
        "\n",
        "### Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "1. **Using Try-Except Blocks:**\n",
        "   - The simplest method of handling exceptions is using `try-except` blocks within each thread or process. This ensures that if an exception occurs, it is caught and handled appropriately.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "JBCYvjpE5yTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Perform some task\n",
        "        raise ValueError(\"An error occurred\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in worker thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqmLTax50hu",
        "outputId": "8cc49812-509f-4892-84ee-2fa06dcc2f1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in worker thread: An error occurred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Handling Exceptions in Thread Pools (`concurrent.futures`):**\n",
        "   - When using thread or process pools (via `concurrent.futures.ThreadPoolExecutor` or `ProcessPoolExecutor`), exceptions raised by tasks can be captured and handled when retrieving the result using the `Future` object.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "eiQ6TKIO6b9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def worker():\n",
        "    raise ValueError(\"Task error\")\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(worker)\n",
        "    try:\n",
        "        result = future.result()  # Will raise exception if the worker fails\n",
        "    except Exception as e:\n",
        "        print(f\"Task failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wEfIS2W6cWt",
        "outputId": "1c4cb34b-50b0-4de6-96e4-7a7e5db10fcf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task failed: Task error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Using Timeout to Monitor Long-Running Tasks:**\n",
        "   - In concurrent programs, tasks may hang or run indefinitely due to unhandled exceptions. You can use timeouts to limit the execution time and catch exceptions when they occur.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "D4yI8XXR6o16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def worker():\n",
        "    # Simulate a long-running task\n",
        "    while True:\n",
        "        pass\n",
        "\n",
        "process = multiprocessing.Process(target=worker)\n",
        "process.start()\n",
        "process.join(timeout=2)  # Timeout after 2 seconds\n",
        "\n",
        "if process.is_alive():\n",
        "    print(\"Terminating process due to timeout\")\n",
        "    process.terminate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDS5ymFP6pqB",
        "outputId": "cee265df-4a0c-4067-da0a-df43bc27cf11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terminating process due to timeout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Propagating Exceptions from Threads/Processes:**\n",
        "   - In some cases, you might want to propagate exceptions from worker threads or processes to the main program. You can re-raise exceptions in the main thread for centralized handling.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "yCudwtbt686t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    raise ValueError(\"Error in worker\")\n",
        "\n",
        "def thread_with_exception():\n",
        "    try:\n",
        "        thread = threading.Thread(target=worker)\n",
        "        thread.start()\n",
        "        thread.join()\n",
        "    except Exception as e:\n",
        "        print(f\"Caught exception: {e}\")\n",
        "\n",
        "thread_with_exception()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE2QnG-M68kq",
        "outputId": "c15b0f0b-c9e4-4e8c-9cc2-6e0e7975b442"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-15 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-15-93680c6096a0>\", line 4, in worker\n",
            "ValueError: Error in worker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Using Exit Handlers and Cleanup (Finally Block):**\n",
        "   - For long-running threads or processes, you should use `try-except-finally` blocks to ensure that resources (like file handles, network connections, or locks) are released properly, even if an exception occurs.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "ieJbba9W7FFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def worker():\n",
        "    try:\n",
        "        # Simulate some work\n",
        "        raise ValueError(\"An error occurred\")\n",
        "    finally:\n",
        "        print(\"Cleaning up resources\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lTflm_z7E1b",
        "outputId": "b0f14348-d025-437f-cc19-d64c0371716d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-16 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-16-7a9976bf1e0c>\", line 4, in worker\n",
            "ValueError: An error occurred\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up resources\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Logging Exceptions:**\n",
        "   - Logging exceptions is critical in concurrent programs since it may be difficult to trace where and why an error occurred. Python’s `logging` module allows you to log exceptions along with tracebacks, which can later help in debugging.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "OoD7GL_E3mE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import threading\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        raise ValueError(\"Error in worker\")\n",
        "    except Exception as e:\n",
        "        logging.error(\"An exception occurred\", exc_info=True)\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwQRXaKq4j8k",
        "outputId": "5ef13f2c-f2d4-46e2-c3ad-745f460f1fb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:An exception occurred\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-17-9563c3781cf5>\", line 8, in worker\n",
            "    raise ValueError(\"Error in worker\")\n",
            "ValueError: Error in worker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Handling Exceptions in Queues:**\n",
        "   - When using queues for communication between threads or processes, exceptions can be passed through the queue for centralized handling in the main thread.\n",
        "   \n",
        "   **Example:**"
      ],
      "metadata": {
        "id": "kZ-1Gsbz4hvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import threading\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        raise ValueError(\"Error in worker\")\n",
        "    except Exception as e:\n",
        "        logging.error(\"An exception occurred\", exc_info=True)\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ4RKLQC4Qbb",
        "outputId": "ecd93c7d-1926-4fd5-bcc5-3804144a1125"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:An exception occurred\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-18-9563c3781cf5>\", line 8, in worker\n",
            "    raise ValueError(\"Error in worker\")\n",
            "ValueError: Error in worker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zVhq-Yyk3mBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "upusQZIuNSFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Here’s a Python program that uses a **thread pool** to calculate the factorial of numbers from 1 to 10 concurrently using `concurrent.futures.ThreadPoolExecutor`.\n",
        "\n",
        "### Python Program Using ThreadPoolExecutor for Factorial Calculation"
      ],
      "metadata": {
        "id": "qVnLn2uaOcQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a number\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a ThreadPoolExecutor\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit tasks to the thread pool\n",
        "        results = [executor.submit(factorial, num) for num in numbers]\n",
        "\n",
        "        # Retrieve and print the results as they complete\n",
        "        for future in concurrent.futures.as_completed(results):\n",
        "            print(f\"Result: {future.result()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xwcoayoOkfs",
        "outputId": "82acdf45-3899-407b-84a5-38a4e559e5f2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1\n",
            "Calculating factorial of 2\n",
            "Calculating factorial of 3\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5Calculating factorial of 6Calculating factorial of 7\n",
            "Calculating factorial of 8\n",
            "\n",
            "Result: 24\n",
            "Result: 2\n",
            "Result: 6\n",
            "Result: 120\n",
            "Result: 5040\n",
            "Result: 40320\n",
            "Result: 1\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "\n",
            "Result: 362880\n",
            "Result: 3628800\n",
            "Result: 720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Explanation:\n",
        "\n",
        "1. **Factorial Function (`factorial`)**:\n",
        "   - The `factorial` function takes a number `n` as input and calculates its factorial using `math.factorial(n)`.\n",
        "\n",
        "2. **ThreadPoolExecutor**:\n",
        "   - We create a thread pool using `ThreadPoolExecutor()`. This manages a pool of threads and automatically assigns tasks to the threads.\n",
        "   - The `submit` method is used to submit tasks (the factorial calculation for each number) to the thread pool. It returns a `Future` object, which can be used to retrieve the result once the task is complete.\n",
        "\n",
        "3. **Handling Results**:\n",
        "   - `concurrent.futures.as_completed(results)` is used to iterate over the `Future` objects as they complete. The `future.result()` method retrieves the result (i.e., the factorial value) for each task."
      ],
      "metadata": {
        "id": "EYS5KM-4NR8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "EufVP_sf3l5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "n-nTiTChPBx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ans. Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken for the computation using different pool sizes (2, 4, and 8 processes).\n",
        "\n",
        "## Python Program Using multiprocessing.Pool for Parallel Computation"
      ],
      "metadata": {
        "id": "CsXzos0wPBn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure the time taken to compute squares using different pool sizes\n",
        "def compute_squares_with_pool_size(pool_size, numbers):\n",
        "    print(f\"\\nUsing pool size: {pool_size}\")\n",
        "\n",
        "    # Create a Pool with the specified size\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.time()  # Record the start time\n",
        "        results = pool.map(square, numbers)  # Perform parallel computation\n",
        "        end_time = time.time()  # Record the end time\n",
        "\n",
        "    # Print the results and the time taken\n",
        "    print(f\"Squares: {results}\")\n",
        "    print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Measure the time for different pool sizes\n",
        "    for pool_size in [2, 4, 8]:\n",
        "        compute_squares_with_pool_size(pool_size, numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVKVdebKPYBv",
        "outputId": "c6c55af3-048b-4277-d7e5-45ca031e86af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using pool size: 2\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0017 seconds\n",
            "\n",
            "Using pool size: 4\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0041 seconds\n",
            "\n",
            "Using pool size: 8\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0054 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "1. **Square Function (`square`)**:\n",
        "   - The `square` function takes a number `n` as input and returns its square (`n * n`).\n",
        "\n",
        "2. **Computing Squares with Different Pool Sizes**:\n",
        "   - The function `compute_squares_with_pool_size` creates a `multiprocessing.Pool` with the specified pool size and uses `pool.map` to distribute the computation of squares across multiple processes.\n",
        "   - The `pool.map` method takes a function (`square`) and a list of numbers (`numbers`), distributing the computations across the available processes in the pool.\n",
        "   - The time taken for the computation is measured using `time.time()` before and after the computation.\n",
        "\n",
        "3. **Main Program**:\n",
        "   - The program calculates the squares of numbers from 1 to 10 using different pool sizes: 2, 4, and 8 processes.\n",
        "   - For each pool size, it calls the `compute_squares_with_pool_size` function, which measures and prints the time taken to compute the squares."
      ],
      "metadata": {
        "id": "usDlDbCW3lv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GekBwnyxPzhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "28gbQn9YP3In"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Thank You"
      ],
      "metadata": {
        "id": "nZT-F0XRP5uR"
      }
    }
  ]
}